{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN via Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv, get_dummies\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "print (keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = read_csv('train.csv')\n",
    "test = read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 1000#42000\n",
    "NUM_CLASSES = 10\n",
    "IMG_WIDTH = 28\n",
    "IMG_HEIGHT = 28\n",
    "IMG_CHANNEL = 1\n",
    "\n",
    "X_all = train.iloc[:SAMPLE_SIZE, 1:].copy()\n",
    "y_all = train.iloc[:SAMPLE_SIZE, 0].copy()\n",
    "X_test = test.copy()\n",
    "\n",
    "X_all = X_all.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "X_all = X_all.values.reshape(-1, IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)\n",
    "X_test = X_test.values.reshape(-1, IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)\n",
    "y_all = get_dummies(y_all.values).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = Sequential()\n",
    "m1.add(Conv2D(filters=32, kernel_size=(5, 5), strides=1, padding='SAME',\n",
    "             activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)))\n",
    "m1.add(Flatten())\n",
    "m1.add(Dropout(0.3))\n",
    "m1.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "m1.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m2 = Sequential()\n",
    "m2.add(Conv2D(filters=32, kernel_size=(5, 5), strides=1, padding='SAME',\n",
    "             activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)))\n",
    "m2.add(Flatten())\n",
    "m2.add(Dropout(0.3))\n",
    "m2.add(Dense(128, activation='relu')) # add\n",
    "m2.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "m2.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m3 = Sequential()\n",
    "m3.add(Conv2D(filters=32, kernel_size=(5, 5), strides=1, padding='SAME',\n",
    "             activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)))\n",
    "m3.add(Conv2D(filters=64, kernel_size=(5, 5), strides=1, padding='SAME',\n",
    "             activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)))\n",
    "m3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "m3.add(Flatten())\n",
    "m3.add(Dropout(0.3))\n",
    "m3.add(Dense(128, activation='relu'))#去掉以后变很差\n",
    "m3.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "m3.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m4 = Sequential()\n",
    "m4.add(Conv2D(filters=32, kernel_size=(5, 5), strides=1, padding='SAME',\n",
    "             activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)))\n",
    "#m4.add(MaxPooling2D(pool_size=(2, 2)))#快了，不过early stopping达到的准确的变小了\n",
    "m4.add(Conv2D(filters=64, kernel_size=(5, 5), strides=1, padding='SAME',\n",
    "             activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)))\n",
    "m4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 没有变更好，有可能是因为数据量不足\n",
    "m4.add(Conv2D(filters=128, kernel_size=(5, 5), strides=1, padding='SAME',\n",
    "             activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)))\n",
    "m4.add(Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='SAME',\n",
    "             activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)))\n",
    "m4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "m4.add(Flatten())\n",
    "m4.add(Dropout(0.3))\n",
    "#m4.add(Dense(1024, activation='relu'))#慢些了（好理解，因为复杂），准确度没变（因为conv提取特征没变，而分类已经到极限）\n",
    "m4.add(Dense(128, activation='relu'))\n",
    "m4.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "m4.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****train on model 3*****\n",
      "\n",
      "Epoch 00000: val_acc improved from -inf to 0.34333, saving model to ./model/m3/checkpoint-00-0.34.hdf5\n",
      "Epoch 00001: val_acc improved from 0.34333 to 0.52333, saving model to ./model/m3/checkpoint-01-0.52.hdf5\n",
      "Epoch 00002: val_acc improved from 0.52333 to 0.71000, saving model to ./model/m3/checkpoint-02-0.71.hdf5\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 00004: val_acc improved from 0.71000 to 0.79000, saving model to ./model/m3/checkpoint-04-0.79.hdf5\n",
      "Epoch 00005: val_acc improved from 0.79000 to 0.79333, saving model to ./model/m3/checkpoint-05-0.79.hdf5\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "*****train on model 4*****\n",
      "\n",
      "Epoch 00000: val_acc improved from -inf to 0.26333, saving model to ./model/m4/checkpoint-00-0.26.hdf5\n",
      "Epoch 00001: val_acc improved from 0.26333 to 0.58333, saving model to ./model/m4/checkpoint-01-0.58.hdf5\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 00003: val_acc improved from 0.58333 to 0.73000, saving model to ./model/m4/checkpoint-03-0.73.hdf5\n",
      "Epoch 00004: val_acc improved from 0.73000 to 0.81333, saving model to ./model/m4/checkpoint-04-0.81.hdf5\n",
      "Epoch 00005: val_acc improved from 0.81333 to 0.85333, saving model to ./model/m4/checkpoint-05-0.85.hdf5\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = './model'\n",
    "EPOCHS = 32\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "tb3 = TensorBoard(log_dir=MODEL_PATH+'/m3/', write_images=True)\n",
    "tb4 = TensorBoard(log_dir=MODEL_PATH+'/m4/', write_images=True)\n",
    "\n",
    "cp3 = ModelCheckpoint(filepath=MODEL_PATH+\"/m3/checkpoint-{epoch:02d}-{val_acc:.2f}.hdf5\", \n",
    "                      monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "cp4 = ModelCheckpoint(filepath=MODEL_PATH+\"/m4/checkpoint-{epoch:02d}-{val_acc:.2f}.hdf5\", \n",
    "                      monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1, verbose=1)\n",
    "\n",
    "print ('\\n*****train on model 3*****\\n')\n",
    "his3 = m3.fit(X_all, y_all, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.3, verbose=0,\n",
    "                  callbacks=[tb3, cp3, early_stopping])\n",
    "print ('\\n*****train on model 4*****\\n')\n",
    "his4 = m4.fit(X_all, y_all, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.3, verbose=0,\n",
    "                  callbacks=[tb4, cp4, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, 2, 2, 7, 0, 3, 0, 3, 5, 7, 4, 0, 4, 5, 2, 1, 9, 0, 9, 1, 1,\n",
       "       5, 7, 4, 2, 7, 7, 7, 7, 5, 4, 2, 6, 2, 9, 5, 1, 6, 7, 7, 4, 9, 8, 7,\n",
       "       8, 8, 6, 7, 6, 8, 8, 3, 8, 2, 1, 2, 4, 0, 4, 1, 7, 0, 0, 0, 1, 9, 0,\n",
       "       1, 6, 5, 8, 8, 2, 8, 3, 9, 2, 3, 5, 4, 1, 0, 9, 2, 4, 3, 6, 7, 2, 0,\n",
       "       6, 6, 1, 4, 3, 9, 7, 4, 0, 8, 2, 0, 7, 3, 0, 5, 0, 9, 0, 0, 4, 2, 1,\n",
       "       2, 1, 1, 8, 3, 3, 7, 2, 8, 6, 3, 8, 7, 8, 4, 3, 5, 6, 0, 0, 0, 3, 1,\n",
       "       3, 6, 4, 3, 4, 5, 5, 8, 7, 7, 2, 8, 4, 3, 5, 6, 5, 3, 7, 5, 7, 8, 3,\n",
       "       0, 4, 5, 1, 8, 7, 6, 3, 0, 2, 7, 8, 6, 1, 3, 7, 4, 1, 2, 4, 8, 5, 2,\n",
       "       4, 9, 2, 1, 6, 0, 6, 1, 4, 4, 6, 0, 9, 7, 6, 9, 1, 9, 0, 9, 9, 0, 8,\n",
       "       4, 6, 2, 0, 9, 3, 6, 7, 2, 1, 6, 3, 4, 2, 3, 1, 0, 2, 8, 4, 6, 1, 0,\n",
       "       0, 4, 9, 1, 2, 3, 2, 3, 8, 6, 8, 6, 2, 8, 5, 5, 4, 8, 3, 8, 9, 7, 1,\n",
       "       3, 8, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.predict_classes(X_test[:BATCH_SIZE], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6400/28000 [=====>........................] - ETA: 118s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c551fb132df6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m submission = pd.DataFrame({\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"ImageId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Terri/code/ml-python-env/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \"\"\"\n\u001b[0;32m-> 1007\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Terri/code/ml-python-env/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Terri/code/ml-python-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1585\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/Terri/code/ml-python-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1210\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Terri/code/ml-python-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Terri/code/ml-python-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Terri/code/ml-python-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Terri/code/ml-python-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/Terri/code/ml-python-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Terri/code/ml-python-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred = m3.predict_classes(X_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "np.savetxt('prediction.csv', np.c_[range(1, len(yPred)+1), yPred], \n",
    "           delimiter=',', header='ImageId,Label', comments='', fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
